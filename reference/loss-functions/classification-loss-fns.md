# Definitions

- Loss: difference between predictions and actual results/values
- Entropy: degree of randomness or disorder
- Cross Entropy: differences between two probability distributions

# Binary Cross-Entropy

# Sparse Categorical Cross-Entropy


# Hinge Loss

Mainly used for max boundary classifications.

Low sensitivity to outlier errors.

# Log Loss


